<!DOCTYPE html>

<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
    <meta charset="utf-8">
<!--[if IE]><meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'><![endif]-->
<meta name="viewport" content="width=device-width,initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Paper Reading - Open-Sora 2.0 | Rain Chen&#39;s Blog</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Paper Reading - Open-Sora 2.0" />
<meta name="author" content="Rain" />
<meta property="og:locale" content="en" />
<meta name="description" content="Paper Reading - Open-Sora 2.0: Training a Commercial-Level Video Generation Model in $200k" />
<meta property="og:description" content="Paper Reading - Open-Sora 2.0: Training a Commercial-Level Video Generation Model in $200k" />
<link rel="canonical" href="https://congjyu.github.io/blog/2025/11/14/Paper-OpenSora/" />
<meta property="og:url" content="https://congjyu.github.io/blog/2025/11/14/Paper-OpenSora/" />
<meta property="og:site_name" content="Rain Chen&#39;s Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-11-14T00:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Paper Reading - Open-Sora 2.0" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Rain"},"dateModified":"2025-11-14T00:00:00+08:00","datePublished":"2025-11-14T00:00:00+08:00","description":"Paper Reading - Open-Sora 2.0: Training a Commercial-Level Video Generation Model in $200k","headline":"Paper Reading - Open-Sora 2.0","mainEntityOfPage":{"@type":"WebPage","@id":"https://congjyu.github.io/blog/2025/11/14/Paper-OpenSora/"},"url":"https://congjyu.github.io/blog/2025/11/14/Paper-OpenSora/"}</script>
<!-- End Jekyll SEO tag -->

<meta name="keywords"
    content="Artificial Intelligence,Papers" />





<link type="application/atom+xml" rel="alternate" href="https://congjyu.github.io/feed.xml" title="Rain Chen&apos;s Blog" />
    <link href='/assets/stylesheets/blog.css' rel="stylesheet" type="text/css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/modernizr/2.8.3/modernizr.min.js"></script>
<script>window.Modernizr || document.write('<script src="/assets/javascripts/modernizr-2.8.3.min.js"><\/script>')</script>

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script>
    window.jQuery || document.write('<script src="/assets/javascripts/jquery-3.3.1.min.js"><\/script>')
</script>

<script src="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js"></script>
<script>
    window.Pace || document.write('<script src="/assets/javascripts/pace.min.js"><\/script>')
</script>
    
</head>

<body>
    

    <!--[if IE]>
    <p class="site-notice">You are using an outdated browser. Please <a href="http://browsehappy.com/" target="_blank">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true" target="_blank">activate Google Chrome Frame</a> to improve your experience.</p>
<![endif]-->
<noscript>
    <p class="site-notice">This site requires JavaScript. Here are the instructions <a href="http://www.enable-javascript.com/" target="_blank">how to enable JavaScript in your web browser</a>.</p>
</noscript>
    <div class="nav-wrapper overlay-wrapper">
    <div class="nav-form overlay-form">
        <span class="overlay-header menu">Menu</span>
        <a class="btn-close">Close</a>
        <div class="results">
            <ul>
                <li><a href="/blog/tags/">Tags</a></li>
                <li><a href="/">About</a></li>
                <li><a href="/blog/centralhk/">Central HK</a></li>
                <li><a href="/blog/friends/">Friends</a></li>
                <li><a href="/blog/aboutme/">About Me</a></li>
            </ul>
        </div>
    </div>
</div>

<div class="search-wrapper overlay-wrapper">
    <div class="search-form overlay-form">
        <input type="text" class="overlay-header search-field"
            placeholder="Search...">
        <a class="btn-close">Close</a>
        <ul class="results"></ul>
    </div>
</div>

    <div id="page" class="hentry">
        <header class="the-header">
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="apple-touch-icon" href="/favicon.ico">
    <div class="unit-head">
        <div class="unit-inner unit-head-inner">
            <nav class="nav-global">
                <ul>
                    <li class="logo nav-link">
                        <button class="btn-menu" title="Menu"></button>
                        <a href="/blog/">Rain Chen's Blog</a>
                        <!--[if !IE]> -->
                        <button class="btn-search" title="Search"></button>
                        <!-- <![endif]-->
                    </li>
                    <li class="nav-link"><a title="Tags"
                            href="/blog/tags/">Tags</a></li>
                    <li class="nav-link"><a title="Central HK"
                            href="/blog/centralhk/">Central HK</a></li>
                    <li class="nav-link"><a title="Friends"
                            href="/blog/friends/">Friends</a></li>
                    <li class="nav-link"><a title="About Me"
                            href="/blog/aboutme/">About Me</a></li>
                    <!--[if !IE]> -->
                    <li class="nav-link"><a title="Search" class="btn-search"
                            href="#">Search</a></li>
                    <!-- <![endif]-->
                </ul>
            </nav>
        </div>
    </div>
</header>
<!-- 数学公式 -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
    type="text/javascript"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
        }
    });
</script>

        <div class="body animated fadeInDown" role="main">
            <div class="unit-body">
                <div class="unit-inner unit-body-inner">
                    <div class="entry-content">
                        <article class="unit-article layout-post">
    <div class="unit-inner unit-article-inner">
        <div itemscope itemtype="http://schema.org/Article" class="content">
            <header>
                <div class="unit-head">
                    <div class="unit-inner unit-head-inner">
                        <h1 class="entry-title" itemprop="name">Paper Reading - Open-Sora 2.0</h1>
                    </div>
                </div>
            </header>
            <div class="bd article-content">
                <div class="entry-content">
                    <div class="meta">
                        <p class="date-publish">
                            Published:
                            <time itemprop="datePublished" class="date-pub updated"
                                title="2025-11-14T00:00:00+08:00" datetime="2025-11-14T00:00:00+08:00">November 14, 2025 </time>
                            by
                            <a class="author" href="/" rel="author" title="Show Author">
                                <span itemprop="author" itemscope itemtype="http://schema.org/Person">
                                    <span itemprop="name">Rain</span>
                                </span>
                            </a>
                            
                            
                        </p>
                        <ul class="list-category list-linear">
                            <li class="list-head">Categories: </li>
                             




                        </ul>
                        <ul class="list-tag list-linear">
                            <li class="list-head">Tags: </li>
                             


<li>
    <a href="/blog/tags/#Artificial-Intelligence"
        title="Artificial Intelligence">Artificial Intelligence <span>3</span></a>
</li>


<li>
    <a href="/blog/tags/#Papers"
        title="Papers">Papers <span>1</span></a>
</li>




                        </ul>
                    </div>
                    <div itemprop="articleBody">
                        <h1 id="heading-paper-reading---open-sora-20-training-a-commercial-level-video-generation-model-in-200k">Paper Reading - Open-Sora 2.0: Training a Commercial-Level Video Generation Model in $200k</h1>

<p>This paper is written by Open-Sora Team.</p>

<h2 id="heading-motivation">Motivation</h2>

<p>Video generation models have achieved remarkable progress in the pass year and the quality of the generated videos are
also improved. But the costs and data quantity of these models increased, and it demands a greater training compute. The
author presented a commercial-level video generation model that only costs $200k.</p>

<p>To evaluate the Open-Sora model, the team has designed a comparing table, which covers three key aspects:</p>

<ul>
  <li>Visual quality</li>
  <li>Prompt adherence</li>
  <li>Motion quanlity</li>
</ul>

<h2 id="heading-model-architecture">Model Architecture</h2>

<p>There are two key components of a video generation model: the autoencoder and the diffusion transformer. For the
autoencoder, Open-Sora is initially trained on HunyuanVideo's VAE and later adapt to the Video DC-AE.</p>

<h3 id="heading-3d-autoencoder">3D Autoencoder</h3>

<p>While training this model, an open source video generation model HunyunVideo VAE is leveraged, and the team developed a
video autoencoder with deep compression to improve efficiency and decrease the costs while maintaining high
reconstruction fidelity, which is called "Video DC-AE".</p>

<p>The overview of Video DC-AE: Each block in encoder introduces spatial downsampling, while temporal downsampling occurs
at blocks 4 and 5, with a corresponding symmetric structure in the decoder. The Video DC-AE encoder consists of three
residual blocks followed by three EfficientViT blocks, with the decoder adopting a symmetrical structure.</p>

<h2 id="heading-why-the-3-main-stages-in-training-process-structured-this-way">Why the 3 main stages in training process structured this way?</h2>

<p>Open-Sora 2.0 uses a <strong>three-stage training pipeline</strong> to achieve commercial-level video generation quality (comparable
to models like HunyuanVideo and Runway Gen-3 Alpha) at dramatically lower cost (~$200k total, 5–10× cheaper than
comparable models). The structure prioritizes efficiency by doing the heavy lifting (learning diverse motion patterns
and semantics) at low resolution with cheaper compute, leveraging strong pre-trained image models, and reserving
expensive high-resolution training for a short final fine-tuning phase.</p>

<p>This avoids the prohibitive costs of training directly on high-resolution data from scratch, where attention complexity
scales quadratically with token count/resolution, and minimizes token processing via a custom Video Deep Compression
Autoencoder (Video DC-AE).</p>

<h3 id="heading-stage-1-low-resolution-text-to-video-t2v-pretraining-256px">Stage 1: Low-Resolution Text-to-Video (T2V) Pretraining (256px)</h3>

<ul>
  <li><strong>What happens</strong>: The model (11B parameters, Diffusion Transformer-based) initializes from Flux (a strong open-source
text-to-image model). It trains as text-to-video on ~70M carefully curated 256px short video clips for 85k iterations.</li>
  <li><strong>Cost</strong>: ~$107.5k (most of the budget).</li>
  <li><strong>Why this stage first</strong>: Low resolution keeps token counts and attention costs very low, allowing the model to
efficiently learn diverse real-world motion patterns and text-video alignment on a massive scale. Starting from a
pretrained T2I model (Flux) massively accelerates convergence instead of training video dynamics from scratch. The
paper states: "we first train on 256px resolution videos, allowing the model to learn diverse motion patterns
efficiently."</li>
</ul>

<h3 id="heading-stage-2-low-resolution-image-to-video-i2v-adaptation-256px">Stage 2: Low-Resolution Image-to-Video (I2V) Adaptation (256px)</h3>

<ul>
  <li><strong>What happens</strong>: Continues from Stage 1 checkpoint, shifts to image-to-video conditioning (first frame provided as
input), training on a higher-quality subset of ~10M 256px clips for 13k iterations.</li>
  <li><strong>Cost</strong>: ~$18.4k.</li>
  <li><strong>Why switch to I2V here</strong>: Image conditioning lets the model reuse powerful pretrained image features (especially
from Flux) and focus purely on temporal/motion modeling. This sets up much more efficient resolution upscaling later.
The authors note that "adapting a model from 256px to 768px resolution is significantly more efficient using an
image-to-video approach" because I2V avoids regenerating the first frame from text at high res (which is harder/less
stable) and instead concentrates compute on coherent motion given a sharp starting image.</li>
</ul>

<h3 id="heading-stage-3-high-resolution-image-to-video-fine-tuning-768px">Stage 3: High-Resolution Image-to-Video Fine-Tuning (768px)</h3>

<ul>
  <li><strong>What happens</strong>: Fine-tunes the Stage 2 checkpoint as I2V (with text+image conditioning supported in the final model)
on ~5M strictly filtered high-quality 768px videos for 13k iterations, using the Video DC-AE for extreme compression (
4× temporal × 32× spatial = 4×32×32 overall, reducing tokens ~16× vs standard VAEs).</li>
  <li><strong>Cost</strong>: ~$73.7k.</li>
  <li><strong>Why only fine-tune at high res, and why I2V</strong>: High resolution is computationally brutal (much higher token counts),
so they limit it to a short, targeted phase with a smaller dataset. Motion priors already learned in low-res stages
transfer well, and I2V focuses effort on refining dynamics/perceptual quality rather than re-learning static
composition. The paper emphasizes: "increasing the resolution significantly improves perceptual quality," but doing it
early would explode costs.</li>
</ul>

<h3 id="heading-overall-rationale-for-the-3-stage-structure">Overall Rationale for the 3-Stage Structure</h3>

<p>The core insight is progressive/curricular training: learn motion cheaply at low res → adapt to stronger image
conditioning → polish at high res only. This + Flux initialization + Video DC-AE compression gives massive savings while
preserving quality stays on par with models trained for millions of dollars. Direct high-res T2V training from scratch,
or doing everything in one stage, would require far more GPU time because of quadratic scaling and poorer convergence.
By decoupling motion learning (low-res) from visual fidelity (high-res fine-tune) and using I2V for the expensive parts,
they achieve 5.2× training throughput gains and &gt;10× inference speedup versus less-compressed alternatives.</p>

<p>In short, the staging is an elegant cost–quality optimization that proves you don't need million-dollar runs to reach
the frontier — you just need to train smart.</p>

                    </div>
                </div>
            </div>
            <footer class="unit-foot">
                <div class="unit-inner unit-foot-inner">
                    <div class="post-buttons">
                        <a class="internal gotop" href="#page" title="Back to Top">Back to Top</a>
                        
                    </div>
                    <nav class="pagination">
                        
                            <a class="internal" rel="prev" href="/blog/2025/10/30/IntelligentSystem/" title=" 'Intelligent System - Notes and Practice'"> ← Intelligent System - Notes and Practice</a>
                        
                        
                    </nav>
                </div>
            </footer>
            <div class="misc-content">
                
            </div>
        </div>
    </div>
</article>

                    </div>
                </div>
            </div>
        </div>
        <footer class="the-footer">
    <div class="unit-foot">
        <div class="unit-inner unit-foot-inner">
            <div class="misc vcard">
                <div class="about">
                    <h4><a href="/">About</a></h4>
                    
                    <p>～食個菠蘿包先啦～</p>
                    
                    
                </div>
                <div class="social-links">
                    
                    
                    <a class="ico-github" href="https://github.com/congjyu" rel="me" target="_blank"
                        title="github"></a>
                    
                    
                    
                    <a class="ico-rss" href="https://congjyu.github.io/feed" rel="me" target="_blank"
                        title="rss"></a>
                    
                    
                </div>
            </div>
        </div>
    </div>
    <a href="#" class="internal back-to-top">Back to Top</a>
</footer>
    </div>

    <script>
    $(document).ready(function () {
        var offset = 50,
            duration = 500,
            width = 960;
        $(window).scroll(function () {
            if ($(window).width() > width) {
                if ($(this).scrollTop() > offset) {
                    $('footer').css('top', '20px');
                    $('footer .back-to-top').fadeIn(duration);
                } else {
                    $('footer').css('top', 'auto');
                    $('footer .back-to-top').fadeOut(duration);
                }
            }
        });
        $(window).resize(function () {
            if ($(window).width() < width) {
                $('footer').css('top', 'auto');
                $('footer .back-to-top').fadeOut(duration);
            }
            if ($(window).width() >= width && $(this).scrollTop() > offset) {
                $('footer').css('top', '20px');
                $('footer .back-to-top').fadeIn(duration);
            }
        });

        $('footer .back-to-top, .gotop').on('click', function (event) {
            event.preventDefault();
            $('html, body').animate({
                scrollTop: 0
            }, duration);
            return false;
        });

        $('.show-hidden').on('click', function () {
            $(this).parent().next().toggleClass("hidden");
            $(this).toggleClass("hidden");
        });
    });
</script>

<!-- Show menu overlay + Jekyll Simple Search option -->
<script src="/assets/javascripts/jekyll-search.jquery.js"></script>
<script>
    $(document).ready(function () {
        $('.search-field').simpleJekyllSearch({
            jsonFile: '/search.json',
            template: '<li><a href="{url}">{title} <span class="entry-date"><time datetime="{date}">{shortdate}</time></span></a></li>',
            searchResults: '.search-wrapper .results',
            searchResultsTitle: '<h4>Search results</h4>',
            noResults: '<p>Oh shucks<br/><small>Nothing found :(</small></p>'
        });
    });

    (function ($, window, undefined) {
        var closeOverlay = function () {
            $('.nav-wrapper, .search-wrapper').removeAttr('style');
            $(".nav-form, .search-form").removeClass('active');
            $("body").removeClass('nav-overlay search-overlay');
        };

        $('.nav-global .btn-search').on('click', function () {
            $('.search-wrapper').css({ display: "block" });
            $(".search-form").addClass('active');
            $(".search-form").find('input').focus();
            $("body").addClass('search-overlay');
        });

        $('.nav-global .btn-menu').on('click', function () {
            $('.nav-wrapper').css({ display: "block" });
            $(".nav-form").addClass('active');
            $(".nav-form .search-field").prop('disabled', true);
            $("body").addClass('nav-overlay');
        });

        $('.nav-wrapper .btn-close, .search-wrapper .btn-close').on('click', function () {
            closeOverlay();
        });

        $(document).on('keyup', function (e) {
            if (e.keyCode === 27) {
                closeOverlay();
            }
        });
    })(jQuery, window);
</script>

<script src='//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js'></script>
<script src='//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-buttons.min.js'></script>
<script src="/assets/javascripts/unveil/jquery.unveil.min.js"></script>

<script>
    window.jQuery.fancybox || document.write('<script src="/assets/javascripts/fancybox/jquery.fancybox.pack.js?v=2.1.4"><\/script>')
    window.jQuery.fancybox.helpers.buttons || document.write('<script src="/assets/javascripts/fancybox/helpers/jquery.fancybox-buttons.js?v=1.0.5"><\/script>')
</script>

<script>
    $("head").append('<link rel="stylesheet" href="/assets/javascripts/fancybox/jquery.fancybox.css?v=2.1.4" type="text/css" />');
    $("head").append('<link rel="stylesheet" href="/assets/javascripts/fancybox/helpers/jquery.fancybox-buttons.css?v=1.0.5" type="text/css" />');
    $(".post-image").fancybox({
        prevEffect: 'none',
        nextEffect: 'none',
        closeBtn: true,
        helpers: {
            title: {
                type: 'float'
            }
        }
    });
    $(document).ready(function () {
        $(".post-image > img").unveil(450);
    });
</script>
</body>

</html>