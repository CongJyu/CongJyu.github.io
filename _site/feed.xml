<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="https://congjyu.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://congjyu.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-11-16T22:10:37+08:00</updated><id>https://congjyu.github.io/feed.xml</id><title type="html">Rain Chen&apos;s Blog</title><subtitle>Rain 嘅個人站點</subtitle><author><name>{&quot;name&quot; =&gt; nil, &quot;job_title&quot; =&gt; nil, &quot;location&quot; =&gt; nil, &quot;email&quot; =&gt; nil, &quot;social_links&quot; =&gt; [{&quot;name&quot; =&gt; &quot;github&quot;, &quot;url&quot; =&gt; &quot;https://github.com/congjyu&quot;}, {&quot;name&quot; =&gt; &quot;rss&quot;, &quot;url&quot; =&gt; &quot;https://congjyu.github.io/feed&quot;}]}</name></author><entry><title type="html">Paper Reading - Open-Sora 2.0</title><link href="https://congjyu.github.io/blog/2025/11/14/Paper-OpenSora/" rel="alternate" type="text/html" title="Paper Reading - Open-Sora 2.0" /><published>2025-11-14T00:00:00+08:00</published><updated>2025-11-14T00:00:00+08:00</updated><id>https://congjyu.github.io/blog/2025/11/14/Paper-OpenSora</id><content type="html" xml:base="https://congjyu.github.io/blog/2025/11/14/Paper-OpenSora/">&lt;h1 id=&quot;heading-paper-reading---open-sora-20-training-a-commercial-level-video-generation-model-in-200k&quot;&gt;Paper Reading - Open-Sora 2.0: Training a Commercial-Level Video Generation Model in $200k&lt;/h1&gt;

&lt;p&gt;This paper is written by Open-Sora Team.&lt;/p&gt;

&lt;h2 id=&quot;heading-motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;Video generation models have achieved remarkable progress in the pass year and the quality of the generated videos are also improved. But the costs and data quantity of these models increased, and it demands a greater training compute. The author presented a commercial-level video generation model that only costs $200k.&lt;/p&gt;

&lt;p&gt;To evaluate the Open-Sora model, the team has designed a comparing table, which covers three key aspects:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Visual quality&lt;/li&gt;
  &lt;li&gt;Prompt adherence&lt;/li&gt;
  &lt;li&gt;Motion quanlity&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;heading-model-architecture&quot;&gt;Model Architecture&lt;/h2&gt;

&lt;p&gt;There are two key components of a video generation model: the autoencoder and the diffusion transformer. For the autoencoder, Open-Sora is initially trained on HunyuanVideo&apos;s VAE and later adapt to the Video DC-AE.&lt;/p&gt;

&lt;h3 id=&quot;heading-3d-autoencoder&quot;&gt;3D Autoencoder&lt;/h3&gt;

&lt;p&gt;While training this model, an open source video generation model HunyunVideo VAE is leveraged, and the team developed a video autoencoder with deep compression to improve efficiency and decrease the costs while maintaining high reconstruction fidelity, which is called &quot;Video DC-AE&quot;.&lt;/p&gt;</content><author><name>Rain</name></author><category term="Artificial Intelligence" /><category term="Papers" /><summary type="html">Paper Reading - Open-Sora 2.0: Training a Commercial-Level Video Generation Model in $200k</summary></entry><entry><title type="html">Intelligent System - Notes and Practice</title><link href="https://congjyu.github.io/blog/2025/10/30/IntelligentSystem/" rel="alternate" type="text/html" title="Intelligent System - Notes and Practice" /><published>2025-10-30T00:00:00+08:00</published><updated>2025-10-30T00:00:00+08:00</updated><id>https://congjyu.github.io/blog/2025/10/30/IntelligentSystem</id><content type="html" xml:base="https://congjyu.github.io/blog/2025/10/30/IntelligentSystem/">&lt;h1 id=&quot;heading-intelligent-system---notes-and-practice&quot;&gt;Intelligent System - Notes and Practice&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Intelligence is a mental quality that consists of the abilities to learn from experience, adapt to new situations, understanding and handle abstract concepts, and use knowledge to manipulate one&apos;s environment.&lt;/p&gt;

  &lt;p&gt;– Britannica&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;heading-a-definition-of-intelligent-systems&quot;&gt;A Definition of Intelligent Systems&lt;/h3&gt;

&lt;p&gt;A system is an intelligent system if the system exhibits some intelligent behaviors. (e.g. fuzzy systems, simulated annealing, genetic algorithms and expert systems.)&lt;/p&gt;

&lt;h2 id=&quot;heading-support-vector-machines-svm&quot;&gt;Support Vector Machines (SVM)&lt;/h2&gt;

&lt;h2 id=&quot;heading-つづく&quot;&gt;つづく…&lt;/h2&gt;</content><author><name>Rain</name></author><category term="CityU" /><category term="Intelligent System" /><category term="Artificial Intelligence" /><category term="Neural Network" /><summary type="html">Intelligent System - Notes and Practice</summary></entry><entry><title type="html">Weird Python</title><link href="https://congjyu.github.io/blog/2025/10/19/WeirdPython/" rel="alternate" type="text/html" title="Weird Python" /><published>2025-10-19T00:00:00+08:00</published><updated>2025-10-19T00:00:00+08:00</updated><id>https://congjyu.github.io/blog/2025/10/19/WeirdPython</id><content type="html" xml:base="https://congjyu.github.io/blog/2025/10/19/WeirdPython/">&lt;h1 id=&quot;heading-weird-python&quot;&gt;Weird Python&lt;/h1&gt;

&lt;h2 id=&quot;heading-introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;I create this article because of the annoying confusing problems I met in the Python code. I have to admit that Python is a awesome programming language however… it DOSE exist some weird problems when coding not carefully. So this passage is used to record the problems and solutions for Python debugging.&lt;/p&gt;

&lt;h2 id=&quot;heading-stable-method-for-patching-functions-in-packages&quot;&gt;Stable Method for Patching Functions in Packages&lt;/h2&gt;

&lt;h3 id=&quot;heading-problem&quot;&gt;Problem&lt;/h3&gt;

&lt;p&gt;Well, here&apos;s the problem. It happened when I was completing my tutorials. The tutorial imported a Python package called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lucent&lt;/code&gt;, which is used to visualize the layers of CNNs. The code was like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;lucent.optvis&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;render&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;lucent.modelzoo.util&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lu_zoo&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It seems normal, but it may run into trouble because I will run this code on Jupyter Notebook (local or online). Then I use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lucent&lt;/code&gt; package to visualize the layers.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ldevice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lu_zoo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_model_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model1_conv_images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model1_conv_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;conv5:0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;conv5:1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;conv5:3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;conv5:7&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;conv5:15&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;conv5:31&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;conv5:63&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;conv5:127&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;lu_zoo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_model_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model1_conv_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;render&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;render_vis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show_image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model1_conv_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;show_imgs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model1_conv_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Then the output cell run into trouble. There should be a beautiful progress bar loading in the output cell showing the current progress of the analyzation, however, the progress bar flashed and disappeared suddenly, leaving some static time text in the output cell. Like the cell below.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;5it/s

second

second

second
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The situation is not what we want.&lt;/p&gt;

&lt;h3 id=&quot;heading-attempts--solution&quot;&gt;Attempts &amp;amp; Solution&lt;/h3&gt;

&lt;p&gt;The solution is simple too. Now the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tqdm&lt;/code&gt; package provides a special module for Jupyter Notebook, so we can use that module to show progress bar in Jupyter Notebook environment. However, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tqdm&lt;/code&gt; package is not import directly and it is import by another package. How can we replace the original &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tqdm&lt;/code&gt; method to the new specified Jupyter Notebook &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tqdm&lt;/code&gt; method?&lt;/p&gt;

&lt;p&gt;Change the code file in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lucent&lt;/code&gt; package and make it use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;notebook.tqdm&lt;/code&gt; directly DOES work… but it seems that it is not that &quot;normal&quot;. (i.e. totally a strange method, does not robust and stable at all). So, any other methods?&lt;/p&gt;

&lt;p&gt;Luckily, there is an elegant way to solve this problem. We import &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sys&lt;/code&gt; the system package first. Then we import the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tqdm.notebook&lt;/code&gt; package. Finally we can &quot;patch&quot; the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tqdm&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tqdm.notebook.tqdm&lt;/code&gt;, and this will help us enable the Jupyter Notebook progress bar.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sys&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tqdm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;notebook&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;modules&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tqdm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;notebook&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Re-run the Jupyter Notebook, and we find that everything goes well.&lt;/p&gt;

&lt;p&gt;Also, this method works well with other situations when some packages need to be change in certain imported packages.&lt;/p&gt;

&lt;h2 id=&quot;heading-つづく&quot;&gt;つづく…&lt;/h2&gt;</content><author><name>Rain</name></author><category term="Python" /><category term="Coding" /><category term="Debug" /><summary type="html">Weird Python</summary></entry><entry><title type="html">Quantitative Trading Notes</title><link href="https://congjyu.github.io/blog/2025/10/18/QuantTrading/" rel="alternate" type="text/html" title="Quantitative Trading Notes" /><published>2025-10-18T00:00:00+08:00</published><updated>2025-10-18T00:00:00+08:00</updated><id>https://congjyu.github.io/blog/2025/10/18/QuantTrading</id><content type="html" xml:base="https://congjyu.github.io/blog/2025/10/18/QuantTrading/">&lt;h1 id=&quot;heading-quantitative-trading-notes&quot;&gt;Quantitative Trading Notes&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;⚠️ Warning: This article &lt;strong&gt;&lt;em&gt;DO NOT&lt;/em&gt;&lt;/strong&gt; provide any investiment advise. There are &lt;strong&gt;&lt;em&gt;RISKS&lt;/em&gt;&lt;/strong&gt; in investment and financial management, and you should be cautious.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;heading-つづく&quot;&gt;つづく…&lt;/h2&gt;</content><author><name>Rain</name></author><category term="Quantitative Trading" /><category term="FinTech" /><summary type="html">Quantitative Trading Notes</summary></entry><entry><title type="html">Explainable AI - Notes and Practice</title><link href="https://congjyu.github.io/blog/2025/10/17/XAI/" rel="alternate" type="text/html" title="Explainable AI - Notes and Practice" /><published>2025-10-17T00:00:00+08:00</published><updated>2025-10-17T00:00:00+08:00</updated><id>https://congjyu.github.io/blog/2025/10/17/XAI</id><content type="html" xml:base="https://congjyu.github.io/blog/2025/10/17/XAI/">&lt;h1 id=&quot;heading-explainable-ai---notes-and-practice&quot;&gt;Explainable AI - Notes and Practice&lt;/h1&gt;

&lt;h2 id=&quot;heading-linear-regression-and-logistic-regression&quot;&gt;Linear Regression and Logistic Regression&lt;/h2&gt;

&lt;p&gt;We make regression because we want to make a &quot;supervise learning&quot;, that is, input observation $\mathbf{x}$ which is typically a vector in $\mathbb{R}^d$ and output a $y \in \mathbb{R}$ which is a real number. Our goal is to predict the output $y$ from input $\mathbf{x}$. That is, learn the function:&lt;/p&gt;

\[y = f(\mathbf{x}) + \epsilon\]

&lt;p&gt;where $\epsilon$ is the noise.&lt;/p&gt;

&lt;p&gt;Then we come to the linear regression.&lt;/p&gt;

&lt;h3 id=&quot;heading-linear-regression&quot;&gt;Linear Regression&lt;/h3&gt;

&lt;p&gt;Given a linear function of the input feature $x$, $f(x) = \omega * x + b$, where $\omega$ is the slope and $b$ is the intercept. Then we observe a noisy output of the function, then $f(x) = \omega * x + b + \epsilon$ where $\epsilon$ is a assumed Gaussian noise.&lt;/p&gt;

&lt;p&gt;We make it to the d-dimension case. The linear combination (also called weighted sum) of $d$ input variables $x_1, …, x_d$. Now we have:&lt;/p&gt;

\[f(x) = \omega_0 + \omega_1 x_1 + \omega_2 x_2 + ... + \omega_d x_d\]

&lt;p&gt;where $x_j$ is the input features, $\omega_j$ is the input feature weights and $\omega_0$ is the intercept.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;KEY ASSUMPTIONS&lt;/strong&gt; of Linear Regression:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linearity&lt;/strong&gt;: Prediction is a linear combination of features. (Obviously, linear effects are easily interpretable; and additivity seperates the effects.)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Normality&lt;/strong&gt;: Errors are normally distributed.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Homoscedasticity&lt;/strong&gt;: Constant variance of errors across feature space.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Independence&lt;/strong&gt;: Each instance is independent. (We do not measure a same thing repeatly.)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fixed Features&lt;/strong&gt;: Features are treated as constants, free of measurement error.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;No Multicollinearity&lt;/strong&gt;: Features should not be strongly correlated.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;heading-ordinary-least-squares-ols&quot;&gt;Ordinary Least Squares (OLS)&lt;/h3&gt;

&lt;p&gt;Suppose we have a linear function:&lt;/p&gt;

\[f(\mathbf{x}) = \mathbf{w}^T \mathbf{x} + b\]

&lt;p&gt;need to estimate the parameter $(\mathbf{w}, b)$ from the data. A method is to fit the parameters by minimizing the squared prediction error on the training set&lt;/p&gt;

\[{\lbrace(\mathbf{x}_i, y_i)\rbrace}^{N}_{i = 1}\]

&lt;p&gt;Like this:&lt;/p&gt;

\[\min_{\mathbf{w}, b}{\sum^{N}_{i = 1}{(y_i - f(x_i))^2}} = \min_{\mathbf{w}, b}{\sum^{N}_{i = 1}{(y_i - (\mathbf{w}^T \mathbf{x}_i + b))^2}}\]

&lt;p&gt;We have a &lt;strong&gt;closed-form solution&lt;/strong&gt; for this. The bias $b$ can be absorbed into $\mathbf{w}$ by redefining:&lt;/p&gt;

\[\mathbf{w} \leftarrow \begin{bmatrix}\mathbf{w}\\b\end{bmatrix}, \mathbf{x} \leftarrow \begin{bmatrix}\mathbf{x}\\1\end{bmatrix}\]

&lt;p&gt;then the minimization problem will be like this:&lt;/p&gt;

\[\min_{\mathbf{w}} ||\mathbf{y} - \mathbf{X}^T \mathbf{w}||^2\]

&lt;p&gt;where $\mathbf{X} = [\mathbf{x_1}, \mathbf{x_2}, …, \mathbf{x_N}]$ is the data matrix and $\mathbf{y} = [y_1, y_2, …, y_N]^T$ is the vector of outputs.&lt;/p&gt;

&lt;p&gt;So we get the closed-form solution.&lt;/p&gt;

\[\mathbf{w}^* = (\mathbf{X}\mathbf{X}^T)^{-1}\mathbf{X}\mathbf{y}\]

&lt;p&gt;The $(\mathbf{X}\mathbf{X}^T)^{-1}\mathbf{X}$ part is also called the pseudo-inverse of $\mathbf{X}$.&lt;/p&gt;

&lt;h3 id=&quot;heading-model-fit-r-square&quot;&gt;Model Fit-R-Square&lt;/h3&gt;

&lt;p&gt;Commonly known as &lt;strong&gt;R-Squared&lt;/strong&gt; ($R^2$), is a statistical measure that shows the proportion of the variance in the dependent variable that can be explained by the independent variables in a regression model. It essentially indicates how well the regression model fits the observed data.&lt;/p&gt;

&lt;p&gt;For the prediction: $\hat{y_i} = f(x_i)$, R-Squared (Coefficient of Determination): proportion of variance is explained by the model.&lt;/p&gt;

\[R^2 = 1 - \frac{SSE}{SST}\]

&lt;p&gt;where the $SSE$ is the Sum of Squared Errors, calculated by&lt;/p&gt;

\[SSE = \sum^{n}_{i = 1}(y_i - \hat{y_i})^2\]

&lt;p&gt;measuring the total squared difference between actual and predicted values; and the $SST$ is the Total Sum of Squares, $SST = \sum^{n}_{i = 1}(y_i - \bar{y})^2$, measuring the total variance in the observed data, and $\bar{y}$ is the mean.&lt;/p&gt;

&lt;p&gt;Now we get $R^2$ can we can make an interpretation. $R^2$ closed to 1 means model explains most of the variance; and $R^2$ closed to 0 means model explains little of the variance.&lt;/p&gt;

&lt;p&gt;Then we have Adjusted R-Squared:&lt;/p&gt;

\[\bar{R}^2 = 1 - (1 - R^2) \frac{n - 1}{n - p - 1}\]

&lt;p&gt;and it adjusts $R^2$ for the number of predictors $p$ and the sample size $n$. Thus, we can use Adjusted R-Squared when comparing models with different numbers of features. Also, Adjusted R-Squared penalizes unnecessary predictors.&lt;/p&gt;

&lt;h2 id=&quot;heading-つづく&quot;&gt;つづく…&lt;/h2&gt;</content><author><name>Rain</name></author><category term="CityU" /><category term="Artificial Intelligence" /><category term="XAI" /><summary type="html">Explainable AI - Notes and Practice</summary></entry></feed>